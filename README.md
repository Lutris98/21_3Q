# 노트북 필사공부
Type|Competition|Link
-|-|-
분류|1.Porto Seguro’s Safe Driver Prediction|<a href="https://www.kaggle.com/bertcarremans/data-preparation-exploration">Data Preparation &amp; Exploration</a></br><a href="https://www.kaggle.com/arthurtok/interactive-porto-insights-a-plot-ly-tutorial">Interactive Porto Insights - A Plot.ly Tutorial</a></br><a href="https://www.kaggle.com/aharless/xgboost-cv-lb-284">XGBoost CV (LB .284)</a></br><a href="https://www.kaggle.com/gpreda/porto-seguro-exploratory-analysis-and-prediction">Porto Seguro Exploratory Analysis and Prediction</a></br>
분류|2.Costa Rican Household Poverty Level Prediction|<a href="https://www.kaggle.com/willkoehrsen/a-complete-introduction-and-walkthrough">A Complete Introduction and Walkthrough </a></br><a href="https://www.kaggle.com/youhanlee/3250feats-532-feats-using-shap-lb-0-436">3250feats-&gt;532 feats using shap[LB: 0.436]</a></br><a href="https://www.kaggle.com/skooch/xgboost">XGBoost</a></br>
분류|3.Home Credit Default Risk|<a href="https://www.kaggle.com/willkoehrsen/start-here-a-gentle-introduction">Introduction: Home Credit Default Risk Competition</a></br><a href="https://www.kaggle.com/willkoehrsen/start-here-a-gentle-introduction">Introduction: Home Credit Default Risk Competition</a></br><a href="https://www.kaggle.com/eliotbarr/stacking-test-sklearn-xgboost-catboost-lightgbm">Stacking Test-Sklearn, XGBoost, CatBoost, LightGBM</a></br><a href="https://www.kaggle.com/jsaguiar/lightgbm-7th-place-solution">LightGBM 7th place solution</a></br>
회귀|4.New York City Taxi Trip Duration|<a href="https://www.kaggle.com/drgilermo/dynamics-of-new-york-city-animation">Dynamics of New York city - Animation</a></br><a href="https://www.kaggle.com/aiswaryaramachandran/eda-baseline-model-0-40-rmse">EDA + Baseline Model</a></br><a href="https://www.kaggle.com/danijelk/beat-the-benchmark">Beat the benchmark!</a></br>
회귀|5.Zillow Prize: Zillow’s Home Value Prediction (Zestimate)|<a href="https://www.kaggle.com/sudalairajkumar/simple-exploration-notebook-zillow-prize">Simple Exploration Notebook - Zillow Prize</a></br><a href="https://www.kaggle.com/anokas/simple-xgboost-starter-0-0655">Simple XGBoost Starter (~0.0655)</a></br><a href="https://www.kaggle.com/viveksrinivasan/zillow-eda-on-missing-values-multicollinearity">Zillow EDA On Missing Values &amp; Multicollinearity</a></br><a href="https://www.kaggle.com/aharless/xgboost-lightgbm-and-ols-and-nn">XGBoost, LightGBM, and OLS and NN</a></br>
NLP|6.Spooky Author Identification|<a href="https://www.kaggle.com/arthurtok/spooky-nlp-and-topic-modelling-tutorial">Spooky NLP and Topic Modelling tutorial</a></br><a href="https://www.kaggle.com/abhishek/approaching-almost-any-nlp-problem-on-kaggle">Approaching (Almost) Any NLP Problem on Kaggle</a></br><a href="https://www.kaggle.com/sudalairajkumar/simple-feature-engg-notebook-spooky-author">Simple Feature Engg Notebook - Spooky Author</a></br>
NLP|7.Mercari Price Suggestion Challenge|<a href="https://www.kaggle.com/thykhuely/mercari-interactive-eda-topic-modelling">Mercari Interactive EDA + Topic Modelling</a><br><a href="https://www.kaggle.com/knowledgegrappler/a-simple-nn-solution-with-keras-0-48611-pl">A simple nn solution with Keras (~0.48611 PL)</a></br><a href="https://www.kaggle.com/rumbok/ridge-lb-0-41944">Ridge (LB 0.41943)</a></br><a href="https://www.kaggle.com/peterhurford/lgb-and-fm-18th-place-0-40604">LGB and FM [18th Place - 0.40604]</a></br>
NLP|8.Toxic Comment Classification Challenge|<a href="https://www.kaggle.com/sbongo/for-beginners-tackling-toxic-using-keras">[For Beginners] Tackling Toxic Using Keras</a></br><a href="https://www.kaggle.com/jagangupta/stop-the-s-toxic-comments-eda">Stop the S@#$ - Toxic Comments EDA</a></br><a href="https://www.kaggle.com/tunguz/logistic-regression-with-words-and-char-n-grams">Logistic regression with words and char n-grams</a></br><a href="https://www.kaggle.com/rhodiumbeng/classifying-multi-label-comments-0-9741-lb">Classifying multi-label comments (0.9741 lb)</a></br>
시각화|9.Kaggle Machine Learning & Data Science Survey 2017|<a href="https://www.kaggle.com/ash316/novice-to-grandmaster">Novice to Grandmaster</a></br><a href="https://www.kaggle.com/mhajabri/what-do-kagglers-say-about-data-science">What do Kagglers say about Data Science ?</a></br><a href="https://www.kaggle.com/hakkisimsek/plotly-tutorial-1">PLOTLY TUTORIAL - 1</a></br>
군집화|10.코로나 데이터 시각화 AI 경진대회|https://dacon.io/competitions/official/235590/overview/
